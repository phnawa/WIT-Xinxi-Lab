{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # plt 用于显示图片\n",
    "import matplotlib.image as img # mpimg 用于读取图片\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import cv2\n",
    "import d2lzh as d2l\n",
    "from mxnet import gluon, init, nd\n",
    "from mxnet.gluon import data as gdata, nn\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = os.walk(\"G:/桌面/chineseminst/train_data/\")\n",
    "for path,d,filelist in g:  \n",
    "    pass\n",
    "train_data=[]\n",
    "for i in range(len(filelist)):\n",
    "    img_temp=img.imread(r'G:/桌面/chineseminst/train_data/%s'%filelist[i])\n",
    "    r,g,b = [img_temp[:,:,i] for i in range(3)]\n",
    "    img_gray = r*0.299+g*0.587+b*0.114\n",
    "    img_gray = (img_gray - img_gray.min()) * (1 / (img_gray.max() - img_gray.min()))\n",
    "    sp=filelist[i].split('_')\n",
    "    label=sp[3].split('.')\n",
    "    temp=[img_gray,int(label[0])]\n",
    "    train_data.append(temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = os.walk(\"G:/桌面/chineseminst/test_data/\")\n",
    "for path,d,filelist in g:  \n",
    "    pass\n",
    "test_data=[]\n",
    "for i in range(len(filelist)):\n",
    "    img_temp=img.imread(r'G:/桌面/chineseminst/test_data/%s'%filelist[i])\n",
    "    r,g,b = [img_temp[:,:,i] for i in range(3)]\n",
    "    img_gray = r*0.299+g*0.587+b*0.114\n",
    "    img_gray = (img_gray - img_gray.min()) * (1 / (img_gray.max() - img_gray.min()))\n",
    "    sp=filelist[i].split('_')\n",
    "    label=sp[3].split('.')\n",
    "    temp=[img_gray,int(label[0])]\n",
    "    test_data.append(temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(nn.Conv2D(channels=6, kernel_size=5, activation='relu'),\n",
    "        nn.MaxPool2D(pool_size=2, strides=2),\n",
    "        nn.Conv2D(channels=16, kernel_size=5, activation='relu'),\n",
    "        nn.MaxPool2D(pool_size=2, strides=2),\n",
    "        # Dense会默认将(批量大小, 通道, 高, 宽)形状的输入转换成\n",
    "        # (批量大小, 通道 * 高 * 宽)形状的输入\n",
    "        nn.Dense(120, activation='sigmoid'),\n",
    "        nn.Dense(84, activation='sigmoid'),\n",
    "        nn.Dense(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 1, 64, 64)\n",
      "conv2 output shape:\t (200, 6, 60, 60)\n",
      "pool2 output shape:\t (200, 6, 30, 30)\n",
      "conv3 output shape:\t (200, 16, 26, 26)\n",
      "pool3 output shape:\t (200, 16, 13, 13)\n",
      "dense3 output shape:\t (200, 120)\n",
      "dense4 output shape:\t (200, 84)\n",
      "dense5 output shape:\t (200, 15)\n"
     ]
    }
   ],
   "source": [
    "train_iter=ImgLoader(train_data,batch_size)\n",
    "net.initialize()\n",
    "for x,y in train_iter:\n",
    "    print(np.array(x).shape)\n",
    "    break\n",
    "x=nd.array(x)\n",
    "for layer in net:\n",
    "    x = layer(x)\n",
    "    print(layer.name, 'output shape:\\t', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImgLoader(data, batch_size, shuffle=True):\n",
    "    if shuffle:\n",
    "        sf_idx = list(range(len(data)))\n",
    "        np.random.shuffle(sf_idx)\n",
    "        data = np.array(data)\n",
    "        data = data[sf_idx]\n",
    "    batch_data = []\n",
    "    batch_label = []\n",
    "    for item in data:\n",
    "        batch_data.append([item[0]])\n",
    "        batch_label.append(int(item[1] - 1))\n",
    "        if len(batch_data) == batch_size:\n",
    "            yield batch_data, batch_label\n",
    "            batch_data = []\n",
    "            batch_label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, ctx):\n",
    "    acc_sum, n = nd.array([0], ctx=ctx), 0\n",
    "    for X, y in data_iter:\n",
    "#         # 如果ctx代表GPU及相应的显存，将数据复制到显存上\n",
    "        X=nd.array(X)\n",
    "        y=nd.array(y)\n",
    "        X, y = X.as_in_context(ctx), y.as_in_context(ctx).astype('float32')\n",
    "        acc_sum += (net(X).argmax(axis=1) == y).sum()\n",
    "        n += y.size\n",
    "    return acc_sum.asscalar() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ch5(net, batch_size, trainer, ctx,\n",
    "              num_epochs):\n",
    "    print('training on', ctx)\n",
    "    loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "    best_acc = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        train_iter = ImgLoader(train_data, batch_size=batch_size)\n",
    "        test_iter = ImgLoader(test_data, batch_size=batch_size,shuffle=False)\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            X=nd.array(X)             \n",
    "            y=nd.array(y)\n",
    "            X, y = X.as_in_context(ctx), y.as_in_context(ctx)\n",
    "            with autograd.record():\n",
    "                y_hat = net(X)\n",
    "                l = loss(y_hat, y).sum()\n",
    "            l.backward()\n",
    "            trainer.step(batch_size)\n",
    "            y = y.astype('float32')\n",
    "            train_l_sum += l.asscalar()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().asscalar()\n",
    "            n += y.size\n",
    "        test_acc = evaluate_accuracy(test_iter, net, ctx)\n",
    "        val_acc = test_acc\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            # save model\n",
    "            net.save_parameters(\"Chinese_minst.params\")\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n",
    "              'time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc,\n",
    "                 time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on gpu(0)\n",
      "epoch 1, loss 2.7243, train acc 0.085, test acc 0.131, time 2.3 sec\n",
      "epoch 2, loss 2.2925, train acc 0.271, test acc 0.381, time 2.3 sec\n",
      "epoch 3, loss 1.8501, train acc 0.411, test acc 0.462, time 2.3 sec\n",
      "epoch 4, loss 1.2439, train acc 0.608, test acc 0.628, time 2.4 sec\n",
      "epoch 5, loss 0.7798, train acc 0.755, test acc 0.800, time 2.5 sec\n",
      "epoch 6, loss 0.5214, train acc 0.830, test acc 0.845, time 2.6 sec\n",
      "epoch 7, loss 0.3781, train acc 0.879, test acc 0.865, time 2.6 sec\n",
      "epoch 8, loss 0.2871, train acc 0.914, test acc 0.904, time 2.8 sec\n",
      "epoch 9, loss 0.5812, train acc 0.859, test acc 0.884, time 2.7 sec\n",
      "epoch 10, loss 0.2241, train acc 0.938, test acc 0.917, time 2.8 sec\n",
      "epoch 11, loss 0.1428, train acc 0.966, test acc 0.912, time 2.9 sec\n",
      "epoch 12, loss 0.1043, train acc 0.979, test acc 0.927, time 2.9 sec\n",
      "epoch 13, loss 0.0894, train acc 0.982, test acc 0.902, time 3.0 sec\n",
      "epoch 14, loss 0.0734, train acc 0.986, test acc 0.944, time 3.1 sec\n",
      "epoch 15, loss 0.4045, train acc 0.916, test acc 0.885, time 3.3 sec\n",
      "epoch 16, loss 0.1357, train acc 0.966, test acc 0.923, time 3.2 sec\n",
      "epoch 17, loss 0.0685, train acc 0.990, test acc 0.945, time 3.2 sec\n",
      "epoch 18, loss 0.0451, train acc 0.995, test acc 0.946, time 3.2 sec\n",
      "epoch 19, loss 0.0334, train acc 0.997, test acc 0.948, time 3.2 sec\n",
      "epoch 20, loss 0.0270, train acc 0.998, test acc 0.949, time 3.3 sec\n",
      "epoch 21, loss 0.0224, train acc 0.999, test acc 0.950, time 3.3 sec\n",
      "epoch 22, loss 0.0189, train acc 0.999, test acc 0.951, time 3.3 sec\n",
      "epoch 23, loss 0.0166, train acc 0.999, test acc 0.953, time 3.5 sec\n",
      "epoch 24, loss 0.0149, train acc 0.999, test acc 0.953, time 3.5 sec\n",
      "epoch 25, loss 0.0135, train acc 0.999, test acc 0.953, time 3.5 sec\n",
      "epoch 26, loss 0.0124, train acc 1.000, test acc 0.953, time 3.7 sec\n",
      "epoch 27, loss 0.0114, train acc 1.000, test acc 0.952, time 3.6 sec\n",
      "epoch 28, loss 0.0107, train acc 1.000, test acc 0.952, time 3.5 sec\n",
      "epoch 29, loss 0.0100, train acc 1.000, test acc 0.953, time 3.8 sec\n",
      "epoch 30, loss 0.0093, train acc 1.000, test acc 0.954, time 4.0 sec\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import autograd, gluon, init, nd\n",
    "from mxnet.gluon import loss as gloss, nn\n",
    "import time\n",
    "ctx = mx.gpu(0)\n",
    "lr, num_epochs = 0.9, 30\n",
    "net.initialize(force_reinit=True, ctx=ctx, init=init.Xavier())\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})\n",
    "train_ch5(net, batch_size, trainer, ctx, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
